---
title: "Human Resources Data Clustering & PC Analysis"
author: "Kar Ng"
date: '2022-05'
output: 
  github_document: 
    toc: true
    toc_depth: 4
always_allow_html: yes
---


## 1 SUMMARY



## 2 R PACKAGES 

```{r, warning=FALSE, message=FALSE}

library(tidyverse)
library(kableExtra)
library(lubridate)
library(skimr)
library(tidytext)
library(factoextra)
library(FactoMineR)
library(cluster)    # For daisy function
library(cowplot)

```



## 3 INTRODUCTION

This project analyses a set of human resource data by applying one of the core machine learning technique, "Principal Components (PC) methods", which belong to the "unsupervised" branch of machine learning domain. 

There are 5 types of principal components methods:

* Principal Component Analysis (PCA)    
* Correspondence Analysis (CA)    
* Multiple Correspondence Analysis (MCA)  
* Factor Analysis of Mixed Data (FAMD)  
* Multiple Factor Analysis (MFA)  

These PC methods are designed for different type of datasets, I would not explain why and how are these methods different from each other here and for which type of datasets but I will apply the most appropriate one for the dataset used in this project.

Principal component methods are typically used for multivariate analysis (MVA) when we are analysing datasets that have many variables. PC methods will quickly help us identifying the most important variables that contribute the most in explaining the variations in the data sets. 

During computation, PC methods will extract all the variations in the multivariate dataframe and expressed them into a few new variables called principal components (there are other inter-changeable terms with similar meaning in this context, such as "dims" or "axes"). After previous step, many special plots of PC will be plotted to understand the result. Important to note that the goal of PC methods is to identify main directions along which the variation is maximal (KASSAMBARA A 2017). 


## 4 DATA PREPARATION

A public dataset called "Human Resources Data Set" by DR.RICH on Kaggle.com has been downloaded for analysis. *Kaggle.com* is a popular website for data science community to share datasets, codes and knowledge. 

This dataset 

### 4.1 Data import

Following code upload the dataset into R.

```{r}
hr <- read.csv("hr_dataset.csv", 
               fileEncoding = "UTF-8-BOM",
               na.strings = T,
               header = T,
               row.names = NULL)

```



### 4.2 Data description

Following is the data dictionary/description of this dataset, downloaded from this link: [Rpubs](https://rpubs.com/rhuebner/hrd_cb_v14), created by the author, Dr. Rich Huebner.

![Data description](https://raw.githubusercontent.com/KAR-NG/hr/main/pic1_data_description.png)

### 4.3 Data exploration

There are 311 rows and 35 columns in the dataset. Following show the variable "type" allocated by R to each of the column (also known as variables or features), along with several starting values of these variables.

```{r}
glimpse(hr)

```
Randomly sample 10 rows of data from the table:

```{r}
sample_n(hr, 10)

```

The first column is a column recording employee names. I have made this column the name of each rows (or known as observation). It is the standard format required for PC methods.  

## 5 DATA CLEANING

The data may seem perfectly to go however numerous important cleaning and manipulation tasks have been identified and will be perfectly completed in this section. 

```{r}
hr <- hr %>% 
  column_to_rownames(var = "Employee_Name")

```




### 5.1 Variables removals

I will be removing some irrelevant or repeated variables that may not help in our analysis to understand the hidden trends in the data. They are:

* EmpID  
* MaritalStatusID  
* GenderID  
* EmpStatusID  
* DeptID  
* PerfScoreID  
* PositionID  
* Zip  
* ManagerID  
* LastPerformanceReview_Date

After removal of above features, the numbers of columns have been reduced from 35 to 25. 

```{r}
hr2 <- hr %>%
  dplyr::select(-EmpID, -MaritalStatusID, -GenderID, -EmpStatusID, -DeptID, -PerfScoreID, -PositionID, -Zip, -ManagerID, -LastPerformanceReview_Date)
  
glimpse(hr2)

```
### 5.2 New Variable: Age

At the year of writing this project is 2022, and therefore the calculation of age will be 2022 minus DOB (date of birth) in the dataset. The DOB will be replaced with "Age".


```{r}
hr2 <- hr2 %>%  
  mutate(yearDOB = substr(DOB, start = 7, stop = 8),
         yearbirth = as.numeric(paste0(19, yearDOB)),
         Age = 2022 - yearbirth) %>%   
  relocate(Age, .after = State) %>% 
  dplyr::select(-DOB, -yearDOB, -yearbirth)

```


Now, the variable "DOB" has been replaced by "Age", 7th variable, and following shows the age of all employees in the dataset. 

```{r}
hr2$Age
```

### 5.3 New Variable: years_worked

There are two variables in the date set: DateofHire and DateofTermination. 

I will compute the days of each employee worked/works by using the date of termination (DateofTermination) minus date of hire (DateofHire), and for present employee I will use today's date (5-May-2022) minus the date of hire to obtain the total number of days worked. 

```{r}

hr2 <- hr2 %>% 
  mutate(DateofHire = mdy(DateofHire),
         DateofTermination = mdy(DateofTermination),
         days_worked = ifelse(is.na(DateofTermination),
                              today() - DateofHire,
                              DateofTermination - DateofHire),
         years_worked = round(days_worked/365, 1)) %>% 
  relocate(years_worked, .after = RaceDesc) %>% 
  dplyr::select(-DateofHire, -DateofTermination, -days_worked)

```

Following shows number of years, with 1 decimal place, worked by each employee in the dataset. 

```{r}
hr2$years_worked

```

### 5.4 Trim

This section trim the unnecessary leading and trailing whitespaces of character variables in the dataset. 

```{r}
hr2 <- hr2 %>% 
  mutate_if(is.character, trimws)

```



### 5.5 Factor conversion

Some "numeric" and "textual" features will need to be converted into "factor" type because of their categorical nature. 

* All textual features that formed by character "chr" in the dataset need conversion. Following shows all of these textual variables in the datasets.       

```{r}
str(hr2 %>% 
  select(is.character))

```
Following codes complete the conversion task for these textual features. 

```{r}
hr2 <- hr2 %>% 
  mutate_if(is.character, as.factor)

```

* With regards to numeric features, features that need to be converted into factor type are MarriedID, FromDiversityJobFairID, Termd, and EmpSatisfaction.

```{r}
str(hr2 %>% 
      select(-is.factor))

```
Following codes complete the conversion task for these selected numerical features.  

```{r}
hr2 <- hr2 %>% 
  mutate(MarriedID = as.factor(MarriedID),
         FromDiversityJobFairID = as.factor(FromDiversityJobFairID),
         Termd = as.factor(Termd),
         EmpSatisfaction = as.factor(EmpSatisfaction))

```

After conversion, we are able to use following code to summaries the dataset. For example, there are 187 of "0" and 124 of "1" for Married ID. The type of this variable has to be in factor form to make this summary feasible. 

Different categories (or known as "level") in each factor variables are now feasible and countable.

```{r}
summary(hr2 %>% 
          dplyr::select(is.factor))

```

### 5.6 CitizenDesc

There are three categories for the variable "CitizenDesc", Eligible NonCitizen (12 employees), Non-Citizen (4 employees) and 295 US Citizen employees. I can't see why I can't merge "Eligible NonCitizen" and "Non-Citizen", and therefore this section will perform this task. 12 of the "Eligible NonCitizen" will be grouped to "Non-Citizen". 

```{r}
hr2 <- hr2 %>% 
  mutate(CitizenDesc = fct_recode(CitizenDesc,
                                  "Non-Citizen" = "Eligible NonCitizen"))

```

Let's check, and the conversion has been completed. 

```{r}
table(hr2$CitizenDesc)

```


### 5.7 HispanicLatino

The HispanicLatino has following 4 categories. 

```{r}
table(hr2$HispanicLatino)
```
The "no" and "Yes" should be a mistake and have to be converted to "No" and "Yes". Following code complete the conversion. 

```{r}
hr2 <- hr2 %>% 
  mutate(HispanicLatino = fct_recode(HispanicLatino,
                                  "No" = "no",
                                  "Yes" = "yes"))
```


Let's check, and the conversion has been completed. 

```{r}
table(hr2$HispanicLatino)

```

### 5.8 Missing data check

This section check missing data ("NA") in the dataset and will be managed accordingly. 

```{r}
skim_without_charts(hr2)
```
From the above function, there is no any missing data detected by the column "n_missing" or by the column "complete_rate".

Alternatively, I can count the number of missing value ("NA") in each column by following code. 

```{r}
colSums(is.na(hr2))

```

There is no any missing data detected.


## 6 VISUALISATION

This section will help to understand data distribution of each variable and more importantly, to detect outliers.

There are different type of outliers, some outliers may arise from typos but some may be real outliers. For example, executive members may have significant higher salary than most of the employees. This section will find and deal with false outliers, which are those that may be resulted from human errors. 
The true outliers would not be an issue in this project, because principal components methods will scale all numerical variables to make all variables comparable, and therefore this step, known as standardisation, will transform these true outliers. 

### 6.1 Numerical variables

Insights from following summary:

* All employees have their days of absences for worked evenly distributed between 0 to 20  
* Most employees have age between 32 to 55  
* Employees were very on time to work but except a few  
* Employees were very engaging with majority of the scores fall between 4 to 5  
* Typical salary range between 50k to 70k approximately  
* There are a small number of employees had many special projects  
* Most employees from this company worked between 5 to 10 years  

```{r, message=FALSE}
# df

df6.1 <- hr2 %>% 
  dplyr::select(-is.factor) %>% 
  pivot_longer(1:7, names_to = "my_var", values_to = "my_values")

# graph

ggplot(df6.1, aes(x = my_values, fill = my_var)) +
  geom_histogram(color = "black") +
  facet_wrap(~my_var, scales = "free") +
  theme_bw() +
  theme(legend.position = "none",
        plot.title = element_text(face = "bold", hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  labs(title = "Visualisation of Numerical variables",
       subtitle = "by Histogram",
       x = "Variables",
       y = "Count")


```

### 6.2 factor variables 1

There are 17 factor variables to look at, I have spread this examination into two parts. In this part "factor variables 1", I will look at the first 9 factor variables and examine the remaining in next section. 

```{r, fig.height=9, fig.width=10, message=FALSE}
# df

df6.2 <- hr2 %>% 
  dplyr::select(is.factor) %>% 
  dplyr::select(-Position) %>% 
  pivot_longer(1:8, names_to = "my_var", values_to = "my_values") %>% 
  group_by(my_var, my_values) %>% 
  summarise(count = n()) %>% 
  ungroup() %>% 
  mutate(label = reorder_within(x = my_values, by = count, within = my_var))

# graph

ggplot(df6.2, aes(y = label, x = count, fill = my_values)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = count), hjust = 1) +
  facet_wrap(~my_var, scales = "free", ) +
  theme_bw() +
  theme(legend.position = "none",
        plot.title = element_text(face = "bold", hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  scale_y_reordered() +
  labs(title = "Visualisation of factor variables 1",
       subtitle = "by Bar chart",
       y = "Variables",
       x = "Count")


```

Following shows the number of workers in each position in the organisation.

```{r, fig.width=8, fig.height=6}
hr2 %>% 
  dplyr::select(Position) %>% 
  group_by(Position) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(y = fct_reorder(Position, count), x = count)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = count), hjust = -0.3) +
  theme_bw() +
  theme(plot.title = element_text(face = "bold", hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  labs(title = "Visualisation of factor variables 1",
       subtitle = "by Bar chart",
       y = "Variables",
       x = "Count") +
  scale_x_continuous(lim = c(0, 140))
  

```


### 6.3 factor variables 2

This section examine the remaining 8 factor variables. 

```{r, fig.height=9, fig.width=10, message=FALSE}
# df

df6.3 <- hr2 %>% 
  dplyr::select(is.factor) %>% 
  pivot_longer(10:17, names_to = "my_var", values_to = "my_values") %>% 
  group_by(my_var, my_values) %>% 
  summarise(count = n()) %>% 
  ungroup() %>% 
  mutate(label = reorder_within(x = my_values, by = count, within = my_var))

# graph

ggplot(df6.3, aes(y = label, x = count, fill = my_values)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = count), hjust = 1) +
  facet_wrap(~my_var, scales = "free", ) +
  theme_bw() +
  theme(legend.position = "none",
        plot.title = element_text(face = "bold", hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  scale_y_reordered() +
  labs(title = "Visualisation of factor variables 1",
       subtitle = "by Bar chart",
       y = "Variables",
       x = "Count")


```


## 7 CLUSTERING






```{r}
gowerdis <- daisy(hr2, metric = "gower")
summary(gowerdis)
class(gowerdis)

```
### 7.1 Hierarchical Clustering

```{r, fig.height=7, fig.width=12}
hr2.hc <- hclust(gowerdis, method = "complete")

fviz_dend(hr2.hc, cex = 0.5)

```



```{r}
group <- cutree(hr2.hc, k = 2)
table(group)

```

```{r, fig.width=12, fig.height=7}
fviz_dend(hr2.hc,
          k = 4,
          rect = T,
          cex = 0.5)

```





### 7.1 PAM

**Optimal K**

```{r}
avg_silhouette <- NA
  for(i in 2:10){
    gower.pam <- pam(gowerdis, diss = T, k = i)
    avg_silhouette[i] <- gower.pam$silinfo$avg.width
  }

avg_silhouette

```
```{r}
plot(avg_silhouette,
     xlab = "Total number of clusters",
     ylab = "Average Silhouette",
     bty = "n")

lines(avg_silhouette)


```
The data is suggested to be divided into 2 clusters, the 2 clusters are well distinguishable from each other. 

Applying the suggested k to perform the PAM again to cluster the dataset into 2 clusters. 

```{r}
gower.pam <- pam(gowerdis, diss = T, k = 2)

```

The dataset now has following two groups of data for cluster 1 and cluster 2. 

```{r}
table(gower.pam$clustering)

```
Adding the clustering data into the original dataset,

```{r}
# Add cluster grouping to data frame and convert this column into factor

hr2_pam <- cbind(hr2, cluster = gower.pam$clustering) %>% 
  mutate(cluster = as.factor(cluster))


```



## 8 PRINCIPAL COMPONENT

Following code saves the cleaned dataset into csv into the allocated file for storage purpose.

```{r}
write.csv(hr2_pam, "hr2_pam.csv")
```

Import the csv file back and a little transformation (convert character variable into factor.)

```{r}

hr_data <- read.csv("hr2_pam.csv", row.names = 1)
hr_data <- hr_data %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(cluster = as.factor(cluster)
         ) 

```

```{r}
kar.famd <- FAMD(hr_data, graph = F)
```

```{r}
fviz_famd_ind(kar.famd, 
              habillage = "cluster",
              repel = T)

```

```{r}
fviz_famd_var(kar.famd)
```







## REFERENCE

KASSAMBARA A 2017, *Practical Guide To Principal Component Methods in R*, Edition 1, sthda.com

Rich Huebner 2020, *Human Resources Data Set*, viewed 2 May 2022, https://www.kaggle.com/datasets/rhuebner/human-resources-data-set?resource=download 

Rich Huebner 2021, *Codebook - HR Dataset v14*, viewed 3 May 2022, https://rpubs.com/rhuebner/hrd_cb_v14

Clustering and dimensionality reduction techniques on the Berlin Airbnb data and the problem of mixed data (n.d.),viewed 15 May 2022 https://rstudio-pubs-static.s3.amazonaws.com/579984_6b9efbf84ee24f00985c29e24265d2ba.html
